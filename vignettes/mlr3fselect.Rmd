---
title: "mlr3fselect"
output: rmarkdown::html_vignette
bibliography: bibliography.bib
vignette: >
  %\VignetteIndexEntry{mlr3fselect}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r, include = FALSE}
library(mlr3)
library(mlr3fselect)
library(mlr3data)
library(mlr3learners)

lgr::get_logger("mlr3")$set_threshold("warn")
```

In this tutorial, we introduce the `mlr3fselect` package by comparing feature
selection methods on the titanic disaster data set. The objective of feature
selection is to enhance the interpretability of the model, speed up the learning
process and increase the predictive performance.

## Titanic data set

The [Titanic data set](https://www.kaggle.com/c/titanic/data) contains data for
887 Titanic passengers, including whether they survived when the titanic sank. 
Our goal will be to predict the survival of the titanic passengers. 

After loading the data set from the `mlr3data` package, we impute the missing
age values with the median age of the passengers and remove `character`
features. We could use feature engineering to create new features from the
`character` features, however we want to focus on feature selection in this
tutorial.

In addition to the `survived` column, the reduced data set contain for each
passenger the following attributes:

* `age` Age 
* `sex` Sex 
* `sib_sp` Number of siblings/ spouses aboard
* `parch` Number of parents/ children aboard
* `fare` Fair paid 
* `pc_class` Passenger class
    
```{r}
data("titanic", package = "mlr3data")

titanic$age[is.na(titanic$age)] = median(titanic$age, na.rm = TRUE)
titanic$embarked[is.na(titanic$embarked)] = "S"
titanic$ticket = NULL
titanic$name = NULL
titanic$cabin = NULL

titanic = titanic[!is.na(titanic$survived),]
```

We construct a binary classification task.

```{r}
task = TaskClassif$new(id = "titanic", backend = titanic, target = "survived", positive = "1")
```

## Model

We use the logistic regression learner provided by the `mlr3learners` package.

```{r}
learner = lrn("classif.log_reg")
```

To evaluate the predictive performance, we choose a `3-fold-cross-validation`
and the classification error as the measure.

```{r}
resampling = rsmp("repeated_cv", folds = 3, repeats =20)
measure = msr("classif.ce")
```

## Classes

The `FSelectInstance` class specifies a general feature selection scenario. It
evualates the feature sets provided by a feature selection algorithm, stores the
results in an archive and offers methods to print the optimization path and best
performing feature set.

The `Terminator*` subclasses determine when to stop the feature selection. In
this example we choose a terminator that stops the feature selection after 10
seconds. The sugar functions `term()` and `terms()` can be used to retrieve
terminators from the `mlr_terminators` dictionary.

```{r}
terminator = term("clock_time", secs = 10)

FSelectInstance$new(task, learner, resampling, measure, terminator)
```

The `FSelect*` subclasses describe the feature selection strategy. The sugar
function `fs()` can be used to retrieve feature selection algorithms from the
`mlr_fselectors` dictionary.

```{r}
mlr_fselectors
```

## Random search

Random search randomly draws feature sets and evaluates them in batches. We
retrieve the `FSelectRandom` class with the `fs()` sugar function and choose the
`evals` terminator. We set the `n_evals` parameter to `10` which means that 10
feature sets are evaluated.

```{r}
set.seed(7832)
terminator = term("evals", n_evals = 10)
instance = FSelectInstance$new(task, learner, resampling, measure, terminator)
fs = fs("random", batch_size = 5)
```

The feature selection is started by passing the `FSelectInstance` object to the
`$select()` method of `FSelectRandom` which generates feature sets. These
features set are internally passed to the `$eval_batch()` method of
`FSelectInstance` which evaluates the feature sets and stores the results in an
archive. This general interaction between the objects of `mlr3fselect` stays the
same for the different feature selection methods. However, the way how new
feature sets are generated differs depending on the chosen `FSelect*` class.

```{r}
fs$select(instance)
```

We access the archive with the `$archive()` method which returns a `data.table`
containing the resampling results of each evaluated feature set with the
corresponding predictive performances.

```{r}
instance$archive()
```

We retrieve the best performing feature set with 

```{r}
instance$result
```

## Sequential forward selection 

We try sequential forward selection. We chose the `stagnation` terminator that
stops the feature selection if the predictive performance does not increase
anymore.

```{r, eval=FALSE}
set.seed(7832)
terminator = term("none")
instance = FSelectInstance$new(task, learner, resampling, measure, terminator)
fs = fs("sequential")

fs$select(instance)
```

```{r, eval=FALSE}
instance$optimization_path(n = 1, m = 1:7)
#>    batch_nr age embarked fare parch pclass sex sib_sp classif.ce
#> 1:        1   0        0    0     0      0   1      0  0.2132435
#> 2:        2   0        0    0     0      0   1      1  0.2093154
#> 3:        3   0        0    0     0      1   1      1  0.2030303
#> 4:        4   0        0    0     1      1   1      1  0.2019080
#> 5:        5   0        0    1     1      1   1      1  0.2048822
#> 6:        6   1        0    1     1      1   1      1  0.2070707
#> 7:        7   1        1    1     1      1   1      1  0.2037037
```
 
```{r, eval=FALSE}
instance$result
#> $feat
#> [1] "parch"  "pclass" "sex"    "sib_sp"
#> 
#> $perf
#> classif.ce 
#>   0.201908
```
 
## Evolutionary

For evolutionary search, we have to define the population and offspring
parameter `mu` and `lambda`.

```{r, eval=FALSE}
set.seed(7832)
terminator = term("evals", n_evals = 120L)
instance = FSelectInstance$new(task, learner, resampling, measure, terminator)
fs = fs("evolutionary", mu = 10, lambda = 20, survival.strategy = "plus")

fs$select(instance)
```

We retrieve the best performing feature set with 

```{r, eval=FALSE}
instance$result
#> $feat
#> [1] "age"    "fare"   "parch"  "pclass" "sex"    "sib_sp"
#> 
#> $perf
#> classif.ce 
#>  0.2070707
```

## Exhaustive Search

Let's try exhaustive search which evaluates every possible feature subset. We
choose the `none` terminator to evaluate all possible feature subsets. The small
number of features and the fast learning time of logistic regression allows us
to evaluate all feature subsets.

```{r, eval=FALSE}
set.seed(7832)
terminator = term("none")
instance = FSelectInstance$new(task, learner, resampling, measure, terminator)
fs = fs("exhaustive")

fs$select(instance)
```

We get the best feature sets in increasing size with

```{r, eval=FALSE}
instance$optimization_path(n = 1, m = 1:7)
#>    batch_nr age embarked fare parch pclass sex sib_sp classif.ce
#> 1:        1   0        0    0     0      0   1      0  0.2132435
#> 2:        2   0        0    0     0      0   1      1  0.2093154
#> 3:        3   0        0    0     0      1   1      1  0.2030303
#> 4:        4   0        0    0     1      1   1      1  0.2019080
#> 5:        5   1        1    0     0      1   1      1  0.2039843
#> 6:        6   1        1    1     0      1   1      1  0.2037037
#> 7:        7   1        1    1     1      1   1      1  0.2037037
```

We retrieve the best performing feature set with

```{r, eval=FALSE}
instance$result
#> $feat
#> [1] "parch"  "pclass" "sex"    "sib_sp"
#> 
#> $perf
#> classif.ce 
#>   0.201908
```

## Nested Resampling

The feature selection should not be performed on the same resampling sets which
are used for evaluating the model itself since this would result in biased
performance estimates [@bischlResamplingMethodsMetaModel2012]. Nested resampling
uses an outer and inner resampling to separate the feature selection from the
performance estimation of the model.

We choose `holdout` validation for the outer resampling loop to get a fixed test
set. The outer training set is passed to the `AutoFSelect` objects to execute
the feature selection. Then the learner is fitted on the outer training set
using the selected feature sets and the performance is evaluated on the outer
test set.

```{r}
resampling_outer = rsmp("holdout")
```

We use  a `5-fold-cross-validation` to evaluate the predictive performance
during the feature selection.

```{r}
resampling_inner = rsmp("cv", folds = 5)
measure = msr("classif.ce")
terminator = term("evals", n_evals = 120)
```

The `AutoFSelect` class inherits from the `Learner` class and starts an
automatic feature selection when a task is passed to the `$train()` method.
 
```{r}
fs_sequential = fs("sequential")
at_sequential = AutoFSelect$new(learner, resampling_inner, measures = measure, terminator, fselect = fs_sequential)
at_sequential$store_fselect_instance = TRUE

fs_evolutionary = fs("evolutionary", mu = 10, lambda = 20, survival.strategy = "plus")
at_evolutionary = AutoFSelect$new(learner, resampling_inner, measures = measure, terminator, fselect = fs_evolutionary )
at_evolutionary$store_fselect_instance = TRUE

fs_random = fs("random")
at_random = AutoFSelect$new(learner, resampling_inner, measures = measure, terminator, fselect = fs_random)
at_random$store_fselect_instance = TRUE
```

We combine each `AutoFSelect` learner with the task and resampling to a
benchmark grid design.

```{r}
design = benchmark_grid(task, list(at_evolutionary, at_sequential, at_random), resampling_outer)
design
```

Now we construct a benchmark call to execute the feature selection and
performance evaluation at once.

```{r, eval=FALSE}
set.seed(7832)
bmr = benchmark(design, store_models = TRUE)
```

We access the performance of the models estimated on the outer resampling test
set.

```{r, eval=FALSE}
bmr$score()
#>    nr          task task_id       learner              learner_id
#> 1:  1 <TaskClassif> titanic <AutoFSelect> classif.log_reg.fselect
#> 2:  2 <TaskClassif> titanic <AutoFSelect> classif.log_reg.fselect
#> 3:  3 <TaskClassif> titanic <AutoFSelect> classif.log_reg.fselect
#>             resampling resampling_id iteration prediction classif.ce
#> 1: <ResamplingHoldout>       holdout         1     <list>  0.2121212
#> 2: <ResamplingHoldout>       holdout         1     <list>  0.1986532
#> 3: <ResamplingHoldout>       holdout         1     <list>  0.1818182
```

In order to access the corresponding feature sets, we subset the `bmr$data` 
data table.

```{r, eval=FALSE}
bmr$data$learner[[1]]$fselect_result
#> $feat
#> [1] "fare"   "parch"  "pclass" "sex"   
#> 
#> $perf
#> classif.ce 
#>  0.2037317

bmr$data$learner[[2]]$fselect_result
#> $feat
#> [1] "fare"   "parch"  "pclass" "sex"    "sib_sp"
#> 
#> $perf
#> classif.ce 
#>  0.1953568

bmr$data$learner[[3]]$fselect_result
#> $feat
#> [1] "age"      "embarked" "fare"     "parch"    "pclass"   "sex"      "sib_sp"  
#> 
#> $perf
#> classif.ce 
#>  0.2037032
```

## Recursive feature elimination

Recrusive feature elemiation utilizes the `importance()` method of learners. In
each iteration the feature with the lowest importance score is droped.

We choose the non-recruvie algorithm (`recursive = FALSE`) which calculates the
feature importance once on the complete feature set. The recrusive version
(`recursive = TRUE`) recomputes the feature importance on the reduced feature
set in every iteration. The chosen algortihm depends on the used learner. In
case of random forest, the reÄ‡omputation in every iteration might result in a
decreased performance [@svetnikApplicationBreimanRandom2004].

```{r, eval=FALSE}
set.seed(7832)
learner = lrn("classif.ranger", importance = "impurity")
terminator = term("none")
instance = FSelectInstance$new(task, learner, resampling, measure, terminator)
fs = fs("rfe", recursive = FALSE)

fs$select(instance)
```

We access the optimization path.

```{r, eval=FALSE}
instance$optimization_path(n = 1, m = 1:7)
#>    batch_nr age embarked fare parch pclass sex sib_sp classif.ce
#> 1:        1   0        0    0     0      0   1      0  0.2132435
#> 2:        2   0        0    0     0      0   1      1  0.2093154
#> 3:        3   0        0    0     0      1   1      1  0.2030303
#> 4:        4   0        0    0     1      1   1      1  0.2019080
#> 5:        5   1        1    0     0      1   1      1  0.2039843
#> 6:        6   1        1    1     0      1   1      1  0.2037037
#> 7:        7   1        1    1     1      1   1      1  0.2037037
```

