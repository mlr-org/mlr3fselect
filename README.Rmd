---
output: github_document
---

```{r, include = FALSE}
lgr::get_logger("mlr3")$set_threshold("warn")
lgr::get_logger("bbotk")$set_threshold("warn")
set.seed(1)
options(datatable.print.class = FALSE, datatable.print.keys = FALSE, width = 200)
```

# mlr3fselect

Package website: [release](https://mlr3fselect.mlr-org.com/) | [dev](https://mlr3fselect.mlr-org.com/dev/)

<!-- badges: start -->
[![tic](https://github.com/mlr-org/mlr3fselect/workflows/tic/badge.svg?branch=main)](https://github.com/mlr-org/mlr3fselect/actions)
[![CRAN Status](https://www.r-pkg.org/badges/version/mlr3fselect)](https://cran.r-project.org/package=mlr3fselect)
[![StackOverflow](https://img.shields.io/badge/stackoverflow-mlr3-orange.svg)](https://stackoverflow.com/questions/tagged/mlr3)
[![Mattermost](https://img.shields.io/badge/chat-mattermost-orange.svg)](https://lmmisld-lmu-stats-slds.srv.mwn.de/mlr_invite/)
[![CodeFactor](https://www.codefactor.io/repository/github/mlr-org/mlr3fselect/badge)](https://www.codefactor.io/repository/github/mlr-org/mlr3fselect)
<!-- badges: end -->

This package provides feature selection for [mlr3](https://mlr3.mlr-org.com).
It offers various feature selection wrappers, e.g. random search and sequential feature selection and different termination criteria can be set and combined.'AutoFSelect' provides a convenient way to perform nested resampling in combination with 'mlr3'.
The package is build on [bbotk](https://github.com/mlr-org/bbotk) which provides a common framework for optimization.
For feature filters and embedded methods, see [mlr3filters](https://mlr3filters.mlr-org.com)

## Resources

* mlr3book [chapter](https://mlr3book.mlr-org.com/fs.html)
* mlr3gallery [post](https://mlr3gallery.mlr-org.com/posts/2020-09-14-mlr3fselect-basic/)
* [cheatsheet](https://cheatsheets.mlr-org.com/mlr3fselect.pdf) 

## Installation

Install the last release from CRAN:

```{r eval = FALSE}
install.packages("mlr3fselect")
```

Install the development version from GitHub:

```{r eval = FALSE}
remotes::install_github("mlr-org/mlr3fselect")
```

## Example

```{r, include = FALSE}
# mute load messages
library("mlr3fselect")
```

### Basic feature selection

```{r}
library("mlr3fselect")

# feature selection on the pima indians diabetes data set
instance = fselect(
  method = "random_search",
  task =  tsk("pima"),
  learner = lrn("classif.rpart"),
  resampling = rsmp("holdout"),
  measure = msr("classif.ce"),
  term_evals = 10,
  batch_size = 5
)

# best performing feature set
instance$result

# all evaluated feature sets
as.data.table(instance$archive)
```


### Automatic feature selection

```{r}
# task
task = tsk("pima")

# construct auto tuner
afs = auto_fselector(
  method = "random_search",
  learner = lrn("classif.rpart"),
  resampling = rsmp("holdout"),
  measure = msr("classif.ce"),
  term_evals = 10,
  batch_size = 5
)

# train/test split
train_set = sample(task$nrow, 0.8 * task$nrow)
test_set = setdiff(seq_len(task$nrow), train_set)

# select features set and fit final model on the complete data set in one go
afs$train(task, row_ids = train_set)

# best performing feature set
afs$fselect_result

# all evaluated feature sets
as.data.table(afs$archive)

# predict new data
afs$predict(task, row_ids = test_set)
```

### Nested resampling

```{r}
# nested resampling
rr = fselect_nested(
  method = "random_search",
  task =  tsk("pima"),
  learner = lrn("classif.rpart"),
  inner_resampling = rsmp("holdout"),
  outer_resampling = rsmp("cv", folds = 3),
  measure = msr("classif.ce"),
  term_evals = 10,
  batch_size = 5
)

# aggregated performance of all outer resampling iterations
rr$aggregate()

# performance scores of the outer resampling
rr$score()

# inner resampling results
extract_inner_fselect_results(rr)

# inner resampling archives
extract_inner_fselect_archives(rr)
```